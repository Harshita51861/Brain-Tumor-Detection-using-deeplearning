{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Final Implementation** ","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# 1. Import Libraries\n# ============================================================\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms, models\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport cv2\nimport torch.nn.functional as F\nimport pandas as pd\nfrom datetime import datetime\n\n# ============================================================\n# 2. Define Dataset Paths (update this to your path)\n# ============================================================\nBASE_DIR = \"/kaggle/input/brain-tumor-mri-dataset\"\nTRAIN_DIR = os.path.join(BASE_DIR, \"Training\")\nTEST_DIR = os.path.join(BASE_DIR, \"Testing\")\n\n# ============================================================\n# 3. Define Classes\n# ============================================================\nCLASSES = ['glioma', 'meningioma', 'notumor', 'pituitary']\n\n# ============================================================\n# 4. Transformations\n# ============================================================\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\n# ============================================================\n# 5. Custom Dataset\n# ============================================================\nclass BrainTumorDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.images = []\n        self.labels = []\n        for idx, cls in enumerate(CLASSES):\n            cls_dir = os.path.join(root_dir, cls)\n            for img_name in os.listdir(cls_dir):\n                img_path = os.path.join(cls_dir, img_name)\n                self.images.append(img_path)\n                self.labels.append(idx)\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n        label = self.labels[idx]\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# ============================================================\n# 6. Load Datasets\n# ============================================================\ntrain_dataset = BrainTumorDataset(TRAIN_DIR, transform=train_transform)\ntest_dataset = BrainTumorDataset(TEST_DIR, transform=test_transform)\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\n# ============================================================\n# 7. Define Model (EfficientNet-B0)\n# ============================================================\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = models.efficientnet_b0(pretrained=True)\n# Modify classifier\nnum_features = model.classifier[1].in_features\nmodel.classifier[1] = nn.Linear(num_features, len(CLASSES))\nmodel = model.to(device)\n\n# ============================================================\n# 8. Training Setup\n# ============================================================\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# ============================================================\n# 9. Train Model and Track Metrics\n# ============================================================\nepochs = 5\ntrain_losses = []\ntrain_accs = []\ntest_losses = []\ntest_accs = []\n\nfor epoch in range(epochs):\n    # Training\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    \n    epoch_train_loss = running_loss / len(train_loader)\n    epoch_train_acc = 100 * correct / total\n    train_losses.append(epoch_train_loss)\n    train_accs.append(epoch_train_acc)\n    \n    # Test (using test set as validation proxy)\n    model.eval()\n    test_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    epoch_test_loss = test_loss / len(test_loader)\n    epoch_test_acc = 100 * correct / total\n    test_losses.append(epoch_test_loss)\n    test_accs.append(epoch_test_acc)\n    \n    print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%, \"\n          f\"Test Loss: {epoch_test_loss:.4f}, Test Acc: {epoch_test_acc:.2f}%\")\n\n# Save model for versioning\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nmodel_path = f\"efficientnet_b0_brain_tumor_{timestamp}.pth\"\ntorch.save(model.state_dict(), model_path)\nprint(f\"Model saved as {model_path} for versioning.\")\n\n# ============================================================\n# 10. Evaluate Model with Confidence and Logging\n# ============================================================\nmodel.eval()\ny_true, y_pred = [], []\nall_images = []\nall_labels = []\nall_confidences = []\nlog_data = []  # For logging\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        probs = F.softmax(outputs, dim=1)\n        confs, preds = torch.max(probs, 1)\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n        all_images.extend(images.cpu())\n        all_labels.extend(labels.cpu().numpy())\n        all_confidences.extend(confs.cpu().numpy())\n        \n        # Log per batch\n        for i in range(len(labels)):\n            log_entry = {\n                'true_label': CLASSES[labels[i].item()],\n                'predicted_label': CLASSES[preds[i].item()],\n                'confidence': confs[i].item()\n            }\n            log_data.append(log_entry)\n\nprint(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, target_names=CLASSES))\n\n# Save logs to CSV\nlog_df = pd.DataFrame(log_data)\nlog_df.to_csv(f\"prediction_logs_{timestamp}.csv\", index=False)\nprint(f\"Prediction logs saved to prediction_logs_{timestamp}.csv\")\n\n# Confusion Matrix\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=CLASSES, yticklabels=CLASSES)\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\n# ============================================================\n# 11. Plot Loss and Accuracy Curves\n# ============================================================\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(test_losses, label='Test Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Loss Curves')\nplt.subplot(1, 2, 2)\nplt.plot(train_accs, label='Train Acc')\nplt.plot(test_accs, label='Test Acc')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Accuracy Curves')\nplt.show()\n\n# ============================================================\n# 12. Bias-Aware Grad-CAM Explainability with Adaptive Sampling\n# ============================================================\n\n# Define Bias-Aware Grad-CAM class (with adaptive sampling via perturbations)\nclass BiasAwareGradCAM:\n    def __init__(self, model, target_layer, num_samples=1, noise_std=0.01):\n        self.model = model\n        self.target_layer = target_layer\n        self.num_samples = num_samples  # Number of perturbations for averaging\n        self.noise_std = noise_std  # Standard deviation for Gaussian noise\n        self.gradients = None\n        self.activations = None\n        \n        # Register hooks\n        self.target_layer.register_forward_hook(self.save_activations)\n        self.target_layer.register_full_backward_hook(self.save_gradients)\n    \n    def save_activations(self, module, input, output):\n        self.activations = output\n    \n    def save_gradients(self, module, grad_input, grad_output):\n        self.gradients = grad_output[0]\n    \n    def generate(self, input_image, class_idx=None):\n        grad_cam_maps = []\n        for _ in range(self.num_samples):\n            # Add Gaussian noise for perturbation (bias-aware sampling)\n            perturbed_image = input_image + torch.randn_like(input_image) * self.noise_std\n            perturbed_image = torch.clamp(perturbed_image, 0, 1)  # Clamp to valid range\n            \n            self.model.eval()\n            # Forward pass\n            output = self.model(perturbed_image)\n            if class_idx is None:\n                class_idx = torch.argmax(output, dim=1).item()\n            \n            # Zero gradients\n            self.model.zero_grad()\n            # Backward pass for the specific class\n            output[:, class_idx].backward()\n            \n            # Compute Grad-CAM\n            weights = torch.mean(self.gradients, dim=(2, 3), keepdim=True)\n            grad_cam = F.relu(torch.sum(weights * self.activations, dim=1)).squeeze()\n            grad_cam = grad_cam.detach().cpu().numpy()  # Detach before converting to numpy\n            \n            # Normalize Grad-CAM\n            grad_cam = np.maximum(grad_cam, 0)\n            grad_cam = grad_cam / (grad_cam.max() + 1e-8)\n            grad_cam_maps.append(grad_cam)\n        \n        # Average over samples for bias-aware explanation\n        avg_grad_cam = np.mean(grad_cam_maps, axis=0)\n        return avg_grad_cam, class_idx, output\n\n# Initialize Bias-Aware Grad-CAM (with 3 samples for adaptive feature sampling)\ntarget_layer = model.features[-1]  # Last conv layer in EfficientNet-B0\ngrad_cam = BiasAwareGradCAM(model, target_layer, num_samples=3, noise_std=0.01)\n\n# Find one example index per class from the test set\nclass_examples = {}\nfor i, label in enumerate(all_labels):\n    if label not in class_examples:\n        class_examples[label] = i\n    if len(class_examples) == len(CLASSES):\n        break\n\n# Generate and plot Bias-Aware Grad-CAM for one example per class, with confidence\nfor class_idx, example_idx in class_examples.items():\n    input_image = all_images[example_idx].unsqueeze(0).to(device)  # Add batch dimension\n    true_label = all_labels[example_idx]\n    \n    grad_cam_map, predicted_class, output = grad_cam.generate(input_image)\n    confidence = F.softmax(output, dim=1)[0, predicted_class].item()\n    \n    # Resize Grad-CAM map to match input image size\n    grad_cam_map = cv2.resize(grad_cam_map, (224, 224))\n    \n    # Convert input image to numpy for visualization\n    input_image_np = np.transpose(input_image.cpu().numpy()[0], (1, 2, 0))\n    input_image_np = (input_image_np - input_image_np.min()) / (input_image_np.max() - input_image_np.min())\n    \n    # Create heatmap\n    heatmap = cv2.applyColorMap(np.uint8(255 * grad_cam_map), cv2.COLORMAP_JET)\n    heatmap = np.float32(heatmap) / 255\n    overlay = heatmap + input_image_np\n    overlay = overlay / np.max(overlay)\n    \n    # Plot with confidence\n    plt.figure(figsize=(15, 5))\n    plt.subplot(1, 3, 1)\n    plt.imshow(input_image_np)\n    plt.title(f\"Original Image\\nTrue: {CLASSES[true_label]}\")\n    plt.axis(\"off\")\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(grad_cam_map, cmap=\"jet\")\n    plt.title(\"Bias-Aware Grad-CAM Heatmap\")\n    plt.axis(\"off\")\n    \n    plt.subplot(1, 3, 3)\n    plt.imshow(overlay)\n    plt.title(f\"Overlay\\nPredicted: {CLASSES[predicted_class]}\\nConfidence: {confidence:.2f}\")\n    plt.axis(\"off\")\n    \n    plt.show()\n\n# ============================================================\n# 13. Simulated Human-in-the-Loop Feedback\n# ============================================================\n# For demonstration: Select one example and simulate feedback\nfeedback_logs = []\nexample_idx = 0  # Use the first example\ninput_image = all_images[example_idx].unsqueeze(0).to(device)\ntrue_label = all_labels[example_idx]\ngrad_cam_map, predicted_class, output = grad_cam.generate(input_image)\nconfidence = F.softmax(output, dim=1)[0, predicted_class].item()\n\n# Simulate clinician feedback (in practice, replace with input from dashboard)\nprint(f\"Example: True: {CLASSES[true_label]}, Predicted: {CLASSES[predicted_class]}, Confidence: {confidence:.2f}\")\nfeedback = input(\"Clinician Feedback (e.g., 'correct', 'incorrect - missed tumor', 'flag bias'): \")  # Simulated input\n\nfeedback_entry = {\n    'example_id': example_idx,\n    'true_label': CLASSES[true_label],\n    'predicted_label': CLASSES[predicted_class],\n    'confidence': confidence,\n    'feedback': feedback\n}\nfeedback_logs.append(feedback_entry)\n\n# Save feedback logs\nfeedback_df = pd.DataFrame(feedback_logs)\nfeedback_df.to_csv(f\"feedback_logs_{timestamp}.csv\", index=False)\nprint(f\"Feedback logs saved to feedback_logs_{timestamp}.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}